{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMW5d9C08gkyd5hG6oD+ed",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush123555/ML_Escapades/blob/main/TFNS_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fNZP7wwm-x0r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Tokenizer():\n",
        "  def __init__(self):\n",
        "    self.table = {}\n",
        "    self.reverse = {}\n",
        "\n",
        "  def getVocab(self):\n",
        "    return len(self.table.keys()) + 1\n",
        "\n",
        "  def fit(self, ds):\n",
        "    j = 1 #0 reserved for padding\n",
        "    for i in range(ds.num_rows):\n",
        "      text = str(ds[i][\"text\"])\n",
        "      text = self.cleanText(text)\n",
        "      for word in text.strip().split():\n",
        "        if word not in self.table:\n",
        "          self.table[word] = j\n",
        "          self.reverse[j] = word\n",
        "          j += 1\n",
        "\n",
        "  def cleanText(self, text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S*\", \" \", text)\n",
        "    text = re.sub(r'\\.$', ' . ', text)\n",
        "    text = re.sub(r'\\. ', ' . ', text)\n",
        "    text = re.sub(r'[:()]', ' ', text)\n",
        "    return text\n",
        "\n",
        "  def single_tokenize(self, element):\n",
        "    ids = []\n",
        "    text = self.cleanText(element[\"text\"])\n",
        "    for word in text.strip().split():\n",
        "      if word in self.table:\n",
        "        ids.append(self.table[word])\n",
        "    return {\"input_ids\" : ids}\n",
        "\n",
        "  def tokenize(self, ds):\n",
        "    return ds.map(self.single_tokenize, batched = False)\n",
        "\n",
        "  def single_decode(self, element):\n",
        "    ids = element[\"input_ids\"]\n",
        "    text = []\n",
        "    for id in ids:\n",
        "      text.append(self.reverse[id])\n",
        "    return {\"output\" : text}\n",
        "\n",
        "  def decode(self, ds):\n",
        "    return ds.map(self.single_decode, batched = False)\n"
      ],
      "metadata": {
        "id": "tacmBONs8YYb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_data(data, labels):\n",
        "  filtered_data = []\n",
        "  filtered_labels = []\n",
        "  filtered_lengths = []\n",
        "\n",
        "  for i, seq in enumerate(data):\n",
        "    if len(seq) > 0:\n",
        "      filtered_data.append(data[i])\n",
        "      filtered_labels.append(labels[i])\n",
        "      filtered_lengths.append(len(seq))\n",
        "\n",
        "  return filtered_data, filtered_labels, torch.tensor(filtered_lengths, dtype = torch.int64)"
      ],
      "metadata": {
        "id": "HoAaDqKT8Ckl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class BatchedDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, labels, lengths):\n",
        "    self.data = pad_sequence(data, batch_first = True )\n",
        "    self.labels = torch.tensor(labels, dtype = torch.long)\n",
        "    self.lengths = lengths\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.labels[idx], self.lengths[idx]"
      ],
      "metadata": {
        "id": "IpIcdC8u9-Wu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds[\"train\"]\n",
        "test_ds = ds[\"validation\"]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit(train_ds)\n",
        "\n",
        "train_ds = tokenizer.tokenize(train_ds)\n",
        "test_ds = tokenizer.tokenize(test_ds)\n",
        "\n",
        "train_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"label\"])\n",
        "test_ds.set_format(type=\"torch\", columns=[\"input_ids\",\"label\"])\n",
        "\n",
        "train_labels = train_ds[\"label\"][:]\n",
        "train_data = train_ds[\"input_ids\"][:]\n",
        "\n",
        "test_labels = test_ds[\"label\"][:]\n",
        "test_data = test_ds[\"input_ids\"][:]\n",
        "\n",
        "train_data, train_labels, train_lengths = filter_data(train_data, train_labels)\n",
        "test_data, test_labels, test_lengths = filter_data(test_data, test_labels)\n",
        "\n",
        "final_train_ds = BatchedDataset(train_data, train_labels, train_lengths)\n",
        "train_dl = DataLoader(final_train_ds, batch_size = 64, shuffle = True)\n",
        "\n",
        "final_test_ds = BatchedDataset(test_data, test_labels, test_lengths)\n",
        "test_dl = DataLoader(final_test_ds, batch_size = 64, shuffle = True)"
      ],
      "metadata": {
        "id": "1OjZ6Epb80iL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super(SentimentRNN, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, 32)\n",
        "    self.RNN = nn.GRU(32, 64, bidirectional = True, batch_first=True)\n",
        "    self.fc1 = nn.Linear(128, 3)\n",
        "    self.Dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x, lens):\n",
        "    x = self.embedding(x)\n",
        "    h0 = torch.zeros(2, x.size(0), 64)\n",
        "    x = pack_padded_sequence(x, lens, batch_first = True, enforce_sorted = False)\n",
        "    _, x = self.RNN(x, h0)\n",
        "    x = torch.cat((x[0], x[1]), dim = 1)\n",
        "    x = self.Dropout(x)\n",
        "    outputs = self.fc1(x)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "Bbv-018sDJo4"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentRNN(tokenizer.getVocab())\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q24xBJ9kHeaM",
        "outputId": "4e321bd8-1dd6-4c92-e0fc-391b0349a5f7",
        "collapsed": true
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(21492, 32)\n",
            "  (RNN): GRU(32, 64, batch_first=True, bidirectional=True)\n",
            "  (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (Dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q95DkEkEEsfe",
        "outputId": "1f45eeea-386b-4873-d53a-925cb8a6d76b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x783bfffa7140>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's calculate Train accuracy\n",
        "\n",
        "def calculate_train_accuracy():\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  for batch_x, batch_y, lens in train_dl:\n",
        "    with torch.no_grad():\n",
        "      output = model(batch_x, lens)\n",
        "\n",
        "    pred = torch.argmax(output, dim = 1)\n",
        "    correct += (pred == batch_y).sum()\n",
        "\n",
        "  return correct / train_lengths.size(0)\n",
        "\n",
        "\n",
        "# Accuracy is 0.9968, which means it is overfitting"
      ],
      "metadata": {
        "id": "Wlko4b2Q6K7L"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's calculate test accuracy\n",
        "\n",
        "def calculate_test_accuracy():\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  for batch_x, batch_y, lens in test_dl:\n",
        "    with torch.no_grad():\n",
        "      output = model(batch_x, lens)\n",
        "\n",
        "    pred = torch.argmax(output, dim = 1)\n",
        "    correct += (pred == batch_y).sum()\n",
        "\n",
        "  return correct / test_lengths.size(0)"
      ],
      "metadata": {
        "id": "p7bjTHTqB4Aq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for batch_x, batch_y, lens in train_dl:\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x, lens)\n",
        "    loss = criterion(output, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch {epoch}: Loss = {epoch_loss}    Train_accuracy: {calculate_train_accuracy()}    Test Accuracy: {calculate_test_accuracy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cDEe7KCH6oo",
        "outputId": "caeb9f9d-978b-4d05-b487-81b912b3e8c2",
        "collapsed": true
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 131.3566222190857    Train_accuracy: 0.6776391863822937    Test Accuracy: 0.6803863644599915\n",
            "Epoch 1: Loss = 113.10533368587494    Train_accuracy: 0.7283782362937927    Test Accuracy: 0.7097858190536499\n",
            "Epoch 2: Loss = 98.00137269496918    Train_accuracy: 0.773770809173584    Test Accuracy: 0.7265854477882385\n",
            "Epoch 3: Loss = 83.08433765172958    Train_accuracy: 0.8259775638580322    Test Accuracy: 0.7236455082893372\n",
            "Epoch 4: Loss = 69.54334226250648    Train_accuracy: 0.8612014055252075    Test Accuracy: 0.7417051792144775\n",
            "Epoch 5: Loss = 55.831190502271056    Train_accuracy: 0.8921270370483398    Test Accuracy: 0.7572448253631592\n",
            "Epoch 6: Loss = 43.73532725870609    Train_accuracy: 0.9321731925010681    Test Accuracy: 0.7555648684501648\n",
            "Epoch 7: Loss = 32.09863857552409    Train_accuracy: 0.9548170566558838    Test Accuracy: 0.7564048767089844\n",
            "Epoch 8: Loss = 22.70220957696438    Train_accuracy: 0.9659293293952942    Test Accuracy: 0.7538849115371704\n",
            "Epoch 9: Loss = 15.922618735581636    Train_accuracy: 0.9834364056587219    Test Accuracy: 0.7324653267860413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The test accuracy is 73.54%, which is great for a vanilla RNN, although our model does overfit on the training data\n",
        "\"\"\"\n",
        "Model:\n",
        "    SentimentRNN(\n",
        "    (embedding): Embedding(21492, 100)\n",
        "    (RNN): RNN(100, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "    (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "  )\n",
        "\n",
        "Accuracy: Train: 99.95%, Test: 73.54%\n",
        "\n",
        "Model:\n",
        "  SentimentRNN(\n",
        "    (embedding): Embedding(21492, 64)\n",
        "    (RNN): RNN(64, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "    (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "  )\n",
        "\n",
        "Accuracy: Train: 99.97% Test: 71.7%\n",
        "\n",
        "Model:\n",
        "    SentimentRNN(\n",
        "    (embedding): Embedding(21492, 64)\n",
        "    (RNN): RNN(64, 16, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "    (fc1): Linear(in_features=32, out_features=3, bias=True)\n",
        "  )\n",
        "\n",
        "Accuracy: Train: 94% Test: 68%\n",
        "\n",
        "Model:\n",
        "    SentimentRNN(\n",
        "    (embedding): Embedding(21492, 32)\n",
        "    (RNN): RNN(32, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "    (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "  )\n",
        "\n",
        "Accuracy: Train: 93.9% Test: 71.3\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dk-nQeLREyXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  LSTM:\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 32)\n",
        "      (RNN): LSTM(32, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "      (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 96.7% Test: 76.7%\n",
        "\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 32)\n",
        "      (RNN): LSTM(32, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "      (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 98.66% Test: 76.4%\n",
        "\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 16)\n",
        "      (RNN): LSTM(16, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "      (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 90.82% Test: 73.16%\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ai7cE31UQ4w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  GRU:\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 16)\n",
        "      (RNN): GRU(16, 32, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "      (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 89.38% Test: 75.17%\n",
        "\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 32)\n",
        "      (RNN): GRU(32, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "      (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 98.9% Test: 76.98%\n",
        "\n",
        "    Model:\n",
        "      SentimentRNN(\n",
        "      (embedding): Embedding(21492, 32)\n",
        "      (RNN): GRU(32, 64, batch_first=True, bidirectional=True)\n",
        "      (Dropout): Dropout(p=0.2, inplace=False)\n",
        "      (fc1): Linear(in_features=128, out_features=3, bias=True)\n",
        "      )\n",
        "\n",
        "    Accuracy: Train: 98.34% Test: 73.24%\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YzOh6qJ6Suwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}